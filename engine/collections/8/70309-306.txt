which is the famous Boltzmann entropy formula when k is Boltzmann 's constant , which may be interpreted as the thermodynamic entropy per nat . There are many ways of demonstrating the equivalence of `` information entropy '' and `` physics entropy '' , that is , the equivalence of `` Shannon entropy '' and `` Boltzmann entropy '' . Nevertheless , some authors argue for dropping the word entropy for the H function of information theory and using Shannon 's other term `` uncertainty '' instead .