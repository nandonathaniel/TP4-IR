One of the problems with the original formulation of the razor is that it only applies to models with the same explanatory power ( i.e. , it only tells us to prefer the simplest of equally good models ) . A more general form of the razor can be derived from Bayesian model comparison , which is based on Bayes factors and can be used to compare models that do n't fit the observations equally well . These methods can sometimes optimally balance the complexity and power of a model . Generally , the exact Occam factor is intractable , but approximations such as Akaike information criterion , Bayesian information criterion , Variational Bayesian methods , false discovery rate , and Laplace 's method are used . Many artificial intelligence researchers are now employing such techniques , for instance through work on Occam Learning or more generally on the Free energy principle .